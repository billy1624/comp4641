{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>is_retweet</th>\n",
       "      <th>is_quote</th>\n",
       "      <th>text</th>\n",
       "      <th>quoted_text</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>hts</th>\n",
       "      <th>mentions</th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>likes</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>original_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-05-01 08:56:31</td>\n",
       "      <td>hopenothate</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>\"RT @hopenothate: It is welcome news that Face...</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256145466695319553</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1256127232222822401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-01 08:56:31</td>\n",
       "      <td>AirunPad</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>\"Bé  bé  bé.... Estem aprenent moltes coses du...</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256145465894199299</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-01 08:56:31</td>\n",
       "      <td>micnogent</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>\"RT @annielahmer: Drogue ? Consanguinité ? Alc...</td>\n",
       "      <td>\"Nous famille Ackermann #StopConfinement parce...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256145466703720448</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1256132734562512898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-01 08:56:32</td>\n",
       "      <td>ver7t</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>\"RT @BaselConnect: https://t.co/Ge2QeANIzE\"</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256145466888241152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1256144372179107840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-01 08:56:32</td>\n",
       "      <td>roottool</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>\"RT @Kantei_Saigai: 【お知らせ】特別定額給付金に関するご案内を掲載しまし...</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256145467051659265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1256006643285819392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500023</th>\n",
       "      <td>2020-05-01 11:44:00</td>\n",
       "      <td>_ArriveAlive</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>\"RT @TruckAndFreight: Truck Driver's Story: \"I...</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256187615017086977</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1256187514823589888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500024</th>\n",
       "      <td>2020-05-01 11:44:00</td>\n",
       "      <td>amandafmoe</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>\"RT @RexChapman: Shut it all down.   The staff...</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256187615113629696</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1256064007418585089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500025</th>\n",
       "      <td>2020-05-01 11:44:00</td>\n",
       "      <td>AmolLakras</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>\"RT @Shail2108: Sir  Leaders &amp;amp; Visionaries...</td>\n",
       "      <td>\"“It’s an opportune time for Indian startups t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256187615101026306</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1256107585482010624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500026</th>\n",
       "      <td>2020-05-01 11:44:00</td>\n",
       "      <td>Wayisee</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>\"RT @RichardBurgon: The UK has had more Corona...</td>\n",
       "      <td>\"\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256187615197396995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1256184006741241857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500027</th>\n",
       "      <td>2020-05-01 11:44:00</td>\n",
       "      <td>kengoodall</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>\"RT @TeaPainUSA: It’s unanimous.  Trump sucks....</td>\n",
       "      <td>\"Poll: Americans in all 50 states say their go...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1256187615138795520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1256045794156822531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500028 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date          user is_retweet is_quote  \\\n",
       "0       2020-05-01 08:56:31   hopenothate       True    False   \n",
       "1       2020-05-01 08:56:31      AirunPad      False    False   \n",
       "2       2020-05-01 08:56:31     micnogent       True     True   \n",
       "3       2020-05-01 08:56:32         ver7t       True    False   \n",
       "4       2020-05-01 08:56:32      roottool       True    False   \n",
       "...                     ...           ...        ...      ...   \n",
       "500023  2020-05-01 11:44:00  _ArriveAlive       True    False   \n",
       "500024  2020-05-01 11:44:00    amandafmoe       True    False   \n",
       "500025  2020-05-01 11:44:00    AmolLakras       True     True   \n",
       "500026  2020-05-01 11:44:00       Wayisee       True    False   \n",
       "500027  2020-05-01 11:44:00    kengoodall       True     True   \n",
       "\n",
       "                                                     text  \\\n",
       "0       \"RT @hopenothate: It is welcome news that Face...   \n",
       "1       \"Bé  bé  bé.... Estem aprenent moltes coses du...   \n",
       "2       \"RT @annielahmer: Drogue ? Consanguinité ? Alc...   \n",
       "3             \"RT @BaselConnect: https://t.co/Ge2QeANIzE\"   \n",
       "4       \"RT @Kantei_Saigai: 【お知らせ】特別定額給付金に関するご案内を掲載しまし...   \n",
       "...                                                   ...   \n",
       "500023  \"RT @TruckAndFreight: Truck Driver's Story: \"I...   \n",
       "500024  \"RT @RexChapman: Shut it all down.   The staff...   \n",
       "500025  \"RT @Shail2108: Sir  Leaders &amp; Visionaries...   \n",
       "500026  \"RT @RichardBurgon: The UK has had more Corona...   \n",
       "500027  \"RT @TeaPainUSA: It’s unanimous.  Trump sucks....   \n",
       "\n",
       "                                              quoted_text  lat long  hts  \\\n",
       "0                                                      \"\"  NaN  NaN  NaN   \n",
       "1                                                      \"\"  NaN  NaN  NaN   \n",
       "2       \"Nous famille Ackermann #StopConfinement parce...  NaN  NaN  NaN   \n",
       "3                                                      \"\"  NaN  NaN  NaN   \n",
       "4                                                      \"\"  NaN  NaN  NaN   \n",
       "...                                                   ...  ...  ...  ...   \n",
       "500023                                                 \"\"  NaN  NaN  NaN   \n",
       "500024                                                 \"\"  NaN  NaN  NaN   \n",
       "500025  \"“It’s an opportune time for Indian startups t...  NaN  NaN  NaN   \n",
       "500026                                                 \"\"  NaN  NaN  NaN   \n",
       "500027  \"Poll: Americans in all 50 states say their go...  NaN  NaN  NaN   \n",
       "\n",
       "       mentions                     tweet_id likes retweets replies  \\\n",
       "0           NaN          1256145466695319553     0        0       0   \n",
       "1           NaN          1256145465894199299     0        0       0   \n",
       "2           NaN          1256145466703720448     0        0       0   \n",
       "3           NaN          1256145466888241152     0        0       0   \n",
       "4           NaN          1256145467051659265     0        0       0   \n",
       "...         ...                          ...   ...      ...     ...   \n",
       "500023      NaN          1256187615017086977     0        0       0   \n",
       "500024      NaN          1256187615113629696     0        0       0   \n",
       "500025      NaN          1256187615101026306     0        0       0   \n",
       "500026      NaN          1256187615197396995     0        0       0   \n",
       "500027      NaN          1256187615138795520     0        0       0   \n",
       "\n",
       "       quote_count    original_tweet_id  \n",
       "0                0  1256127232222822401  \n",
       "1                0                  NaN  \n",
       "2                0  1256132734562512898  \n",
       "3                0  1256144372179107840  \n",
       "4                0  1256006643285819392  \n",
       "...            ...                  ...  \n",
       "500023           0  1256187514823589888  \n",
       "500024           0  1256064007418585089  \n",
       "500025           0  1256107585482010624  \n",
       "500026           0  1256184006741241857  \n",
       "500027           0  1256045794156822531  \n",
       "\n",
       "[500028 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'corona/out_502.csv'\n",
    "sentiment_out = 'corona/out_502_sentiment.csv'\n",
    "sentiment_date_out = 'corona/out_502_sentiment_date.csv'\n",
    "gordon_df = pd.read_csv(filename, encoding='utf8', dtype=str, escapechar='\\\\',error_bad_lines=False,engine='python',quoting=csv.QUOTE_NONE)\n",
    "# gordon_df = gordon_df[:50000].copy()\n",
    "gordon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gordon_df = gordon_df.sample(frac=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14544</th>\n",
       "      <td>2020-05-01 09:01:26</td>\n",
       "      <td>Mbhoy1</td>\n",
       "      <td>\"RT @StrongerStabler: \"We have so far succeede...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335359</th>\n",
       "      <td>2020-05-01 10:49:05</td>\n",
       "      <td>luiginamoscuzza</td>\n",
       "      <td>\"RT @EFEnoticias: 🔴📡 R.p. tras la reunión del ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382831</th>\n",
       "      <td>2020-05-01 11:04:55</td>\n",
       "      <td>KirkshawsPS</td>\n",
       "      <td>\"RT @SocSecScot: Have you applied for benefits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175141</th>\n",
       "      <td>2020-05-01 09:55:30</td>\n",
       "      <td>bfsinews</td>\n",
       "      <td>\"RT @dipaksamanta: #COVID19 and Pune : except ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356541</th>\n",
       "      <td>2020-05-01 10:56:09</td>\n",
       "      <td>CSatyarthi</td>\n",
       "      <td>\"Share to save lives Financial Assistance for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276318</th>\n",
       "      <td>2020-05-01 10:29:23</td>\n",
       "      <td>PuneZp</td>\n",
       "      <td>\"#PuneFightsCorona #WarAgainstVirus\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415091</th>\n",
       "      <td>2020-05-01 11:15:41</td>\n",
       "      <td>LeXavTwit</td>\n",
       "      <td>\"Spanish official apologises for spraying beac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125755</th>\n",
       "      <td>2020-05-01 09:38:53</td>\n",
       "      <td>KongKongKong16</td>\n",
       "      <td>\"RT @guardian: Armed protesters enter Michigan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255973</th>\n",
       "      <td>2020-05-01 10:22:34</td>\n",
       "      <td>aaaaa67763912</td>\n",
       "      <td>\"RT @NewsDigestWeb: 【福岡県の感染者推移】  ※1日発表の北九州市内のP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99447</th>\n",
       "      <td>2020-05-01 09:30:03</td>\n",
       "      <td>TheAfrican12</td>\n",
       "      <td>\"RT @FrankMtetezi: So who thought that AFRICA ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125007 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date             user  \\\n",
       "14544   2020-05-01 09:01:26           Mbhoy1   \n",
       "335359  2020-05-01 10:49:05  luiginamoscuzza   \n",
       "382831  2020-05-01 11:04:55      KirkshawsPS   \n",
       "175141  2020-05-01 09:55:30         bfsinews   \n",
       "356541  2020-05-01 10:56:09       CSatyarthi   \n",
       "...                     ...              ...   \n",
       "276318  2020-05-01 10:29:23           PuneZp   \n",
       "415091  2020-05-01 11:15:41        LeXavTwit   \n",
       "125755  2020-05-01 09:38:53   KongKongKong16   \n",
       "255973  2020-05-01 10:22:34    aaaaa67763912   \n",
       "99447   2020-05-01 09:30:03     TheAfrican12   \n",
       "\n",
       "                                                     text  \n",
       "14544   \"RT @StrongerStabler: \"We have so far succeede...  \n",
       "335359  \"RT @EFEnoticias: 🔴📡 R.p. tras la reunión del ...  \n",
       "382831  \"RT @SocSecScot: Have you applied for benefits...  \n",
       "175141  \"RT @dipaksamanta: #COVID19 and Pune : except ...  \n",
       "356541  \"Share to save lives Financial Assistance for ...  \n",
       "...                                                   ...  \n",
       "276318               \"#PuneFightsCorona #WarAgainstVirus\"  \n",
       "415091  \"Spanish official apologises for spraying beac...  \n",
       "125755  \"RT @guardian: Armed protesters enter Michigan...  \n",
       "255973  \"RT @NewsDigestWeb: 【福岡県の感染者推移】  ※1日発表の北九州市内のP...  \n",
       "99447   \"RT @FrankMtetezi: So who thought that AFRICA ...  \n",
       "\n",
       "[125007 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gordon_df = gordon_df[['date', 'user','text']].copy()\n",
    "gordon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterUrl(df):\n",
    "    import time\n",
    "    time_start = time.time()\n",
    "    print(\"  -> filterUrl()\", end='')\n",
    "    \n",
    "    url_regex = r'^RT @\\w+:'\n",
    "    df['text'] = df['text'].str.replace(url_regex, '').astype(str)\n",
    "    \n",
    "    processed = len(df.index)\n",
    "    time = time.time() - time_start\n",
    "    print(\" - Processed: {:,} | Time: {:,.3f} sec\".format(processed, time))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filterUrl2(df):\n",
    "    import time\n",
    "    time_start = time.time()\n",
    "    print(\"  -> filterUrl()\", end='')\n",
    "    \n",
    "    url_regex = r'@\\w+'\n",
    "    df['text'] = df['text'].str.replace(url_regex, '').astype(str)\n",
    "    \n",
    "    processed = len(df.index)\n",
    "    time = time.time() - time_start\n",
    "    print(\" - Processed: {:,} | Time: {:,.3f} sec\".format(processed, time))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filterUrl3(df):\n",
    "    import time\n",
    "    time_start = time.time()\n",
    "    print(\"  -> filterUrl()\", end='')\n",
    "    \n",
    "    url_regex = r'#\\w+'\n",
    "    df['text'] = df['text'].str.replace(url_regex, '').astype(str)\n",
    "    \n",
    "    processed = len(df.index)\n",
    "    time = time.time() - time_start\n",
    "    print(\" - Processed: {:,} | Time: {:,.3f} sec\".format(processed, time))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filterUrl4(df):\n",
    "    import time\n",
    "    time_start = time.time()\n",
    "    print(\"  -> filterUrl()\", end='')\n",
    "    \n",
    "    url_regex = r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\), ]|(?:%[0-9a-fA-F][0-9a-fA-F]))+'\n",
    "    df['text'] = df['text'].str.replace(url_regex, '').astype(str)\n",
    "    \n",
    "    processed = len(df.index)\n",
    "    time = time.time() - time_start\n",
    "    print(\" - Processed: {:,} | Time: {:,.3f} sec\".format(processed, time))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filterUrl5(df):\n",
    "    import time\n",
    "    time_start = time.time()\n",
    "    print(\"  -> filterUrl()\", end='')\n",
    "    \n",
    "    url_regex = r'^\"'\n",
    "    df['text'] = df['text'].str.replace(url_regex, '').astype(str)\n",
    "    \n",
    "    processed = len(df.index)\n",
    "    time = time.time() - time_start\n",
    "    print(\" - Processed: {:,} | Time: {:,.3f} sec\".format(processed, time))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filterUrl6(df):\n",
    "    import time\n",
    "    time_start = time.time()\n",
    "    print(\"  -> filterUrl()\", end='')\n",
    "    \n",
    "    url_regex = r'\"$'\n",
    "    df['text'] = df['text'].str.replace(url_regex, '').astype(str)\n",
    "    \n",
    "    processed = len(df.index)\n",
    "    time = time.time() - time_start\n",
    "    print(\" - Processed: {:,} | Time: {:,.3f} sec\".format(processed, time))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def filterDuplicate(df):\n",
    "    import time\n",
    "    time_start = time.time()\n",
    "    print(\"  -> filterDuplicate()\", end='')\n",
    "    \n",
    "    remove = df.duplicated(keep='first')\n",
    "    result = df[~remove]\n",
    "    \n",
    "#     print(\"Removed: {} \\n\".format(df[remove].head()))\n",
    "    \n",
    "    processed = len(df.index)\n",
    "    skipped = processed - len(result.index)\n",
    "    skipped_percentage = skipped / processed * 100\n",
    "    \n",
    "    time = time.time() - time_start\n",
    "    print(\" - Processed: {:,} | Skipped: {:,} ({:.2f}%) | Time: {:,.3f} sec\".format(processed, skipped, skipped_percentage, time))\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "import demoji\n",
    "\n",
    "def checkNonEngAndEmoji(row):\n",
    "    text = row['text']\n",
    "    text_emoji = demoji.replace(text, '')\n",
    "    row['text'] = text_emoji\n",
    "        \n",
    "    return row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> filterDuplicate() - Processed: 125,007 | Skipped: 22 (0.02%) | Time: 0.287 sec\n",
      "  -> filterUrl() - Processed: 124,985 | Time: 0.560 sec\n",
      "  -> filterUrl() - Processed: 124,985 | Time: 0.290 sec\n",
      "  -> filterUrl() - Processed: 124,985 | Time: 0.454 sec\n",
      "  -> filterUrl() - Processed: 124,985 | Time: 0.267 sec\n",
      "  -> filterUrl() - Processed: 124,985 | Time: 0.263 sec\n",
      "  -> filterUrl() - Processed: 124,985 | Time: 0.287 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14544</th>\n",
       "      <td>2020-05-01 09:01:26</td>\n",
       "      <td>Mbhoy1</td>\n",
       "      <td>\"We have so far succeeded - in the first &amp;amp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335359</th>\n",
       "      <td>2020-05-01 10:49:05</td>\n",
       "      <td>luiginamoscuzza</td>\n",
       "      <td>R.p. tras la reunión del Comité de Gestión T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382831</th>\n",
       "      <td>2020-05-01 11:04:55</td>\n",
       "      <td>KirkshawsPS</td>\n",
       "      <td>Have you applied for benefits from the DWP or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175141</th>\n",
       "      <td>2020-05-01 09:55:30</td>\n",
       "      <td>bfsinews</td>\n",
       "      <td>and Pune : except 5 wards  rest of the  to o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356541</th>\n",
       "      <td>2020-05-01 10:56:09</td>\n",
       "      <td>CSatyarthi</td>\n",
       "      <td>Share to save lives Financial Assistance for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276318</th>\n",
       "      <td>2020-05-01 10:29:23</td>\n",
       "      <td>PuneZp</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415091</th>\n",
       "      <td>2020-05-01 11:15:41</td>\n",
       "      <td>LeXavTwit</td>\n",
       "      <td>Spanish official apologises for spraying beach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125755</th>\n",
       "      <td>2020-05-01 09:38:53</td>\n",
       "      <td>KongKongKong16</td>\n",
       "      <td>Armed protesters enter Michigan's state capit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>255973</th>\n",
       "      <td>2020-05-01 10:22:34</td>\n",
       "      <td>aaaaa67763912</td>\n",
       "      <td>【福岡県の感染者推移】  ※1日発表の北九州市内のPCR検査結果は44件全て陰性  詳細は...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99447</th>\n",
       "      <td>2020-05-01 09:30:03</td>\n",
       "      <td>TheAfrican12</td>\n",
       "      <td>So who thought that AFRICA can also give a so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124985 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date             user  \\\n",
       "14544   2020-05-01 09:01:26           Mbhoy1   \n",
       "335359  2020-05-01 10:49:05  luiginamoscuzza   \n",
       "382831  2020-05-01 11:04:55      KirkshawsPS   \n",
       "175141  2020-05-01 09:55:30         bfsinews   \n",
       "356541  2020-05-01 10:56:09       CSatyarthi   \n",
       "...                     ...              ...   \n",
       "276318  2020-05-01 10:29:23           PuneZp   \n",
       "415091  2020-05-01 11:15:41        LeXavTwit   \n",
       "125755  2020-05-01 09:38:53   KongKongKong16   \n",
       "255973  2020-05-01 10:22:34    aaaaa67763912   \n",
       "99447   2020-05-01 09:30:03     TheAfrican12   \n",
       "\n",
       "                                                     text  \n",
       "14544    \"We have so far succeeded - in the first &amp...  \n",
       "335359    R.p. tras la reunión del Comité de Gestión T...  \n",
       "382831   Have you applied for benefits from the DWP or...  \n",
       "175141    and Pune : except 5 wards  rest of the  to o...  \n",
       "356541  Share to save lives Financial Assistance for C...  \n",
       "...                                                   ...  \n",
       "276318                                                     \n",
       "415091  Spanish official apologises for spraying beach...  \n",
       "125755   Armed protesters enter Michigan's state capit...  \n",
       "255973   【福岡県の感染者推移】  ※1日発表の北九州市内のPCR検査結果は44件全て陰性  詳細は...  \n",
       "99447    So who thought that AFRICA can also give a so...  \n",
       "\n",
       "[124985 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gordon_df = filterDuplicate(gordon_df).copy()\n",
    "gordon_df = filterUrl5(gordon_df)\n",
    "gordon_df = filterUrl6(gordon_df)\n",
    "gordon_df = filterUrl(gordon_df)\n",
    "gordon_df = filterUrl2(gordon_df)\n",
    "gordon_df = filterUrl3(gordon_df)\n",
    "gordon_df = filterUrl4(gordon_df)\n",
    "gordon_df = gordon_df.apply(checkNonEngAndEmoji, axis=1)\n",
    "gordon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langdetect import detect\n",
    "import langid\n",
    "\n",
    "def checklang(row):\n",
    "    re = langid.classify(row['text'])[0]\n",
    "    if(re == \"en\"):\n",
    "        row['is_eng'] = 'True'\n",
    "    else:\n",
    "        row['is_eng'] = 'False'\n",
    "        \n",
    "    return row\n",
    "\n",
    "\n",
    "def filtereng(df):\n",
    "    import time\n",
    "    time_start = time.time()\n",
    "    print(\"  -> filter_eng()\", end='')\n",
    "    \n",
    "    df['is_eng'] = 'False'\n",
    "    \n",
    "    df = df.apply(checklang, axis=1)\n",
    "    \n",
    "    #remove = df.with_sentiment.isin(['False'])\n",
    "    #result = df[~remove]\n",
    "    result = df\n",
    "    \n",
    "    processed = len(df.index)\n",
    "    skipped = processed - len(result.index)\n",
    "    skipped_percentage = skipped / processed * 100\n",
    "    time_used = time.time() - time_start\n",
    "    print(\" - Processed: {:,} | Non-Eng Skipped: {:,} ({:.2f}%) | Time: {:,.3f} sec\".format(processed, skipped, skipped_percentage, time_used))\n",
    "    \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  -> filter_eng() - Processed: 124,985 | Non-Eng Skipped: 0 (0.00%) | Time: 461.829 sec\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14544</th>\n",
       "      <td>2020-05-01 09:01:26</td>\n",
       "      <td>Mbhoy1</td>\n",
       "      <td>\"We have so far succeeded - in the first &amp;amp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382831</th>\n",
       "      <td>2020-05-01 11:04:55</td>\n",
       "      <td>KirkshawsPS</td>\n",
       "      <td>Have you applied for benefits from the DWP or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175141</th>\n",
       "      <td>2020-05-01 09:55:30</td>\n",
       "      <td>bfsinews</td>\n",
       "      <td>and Pune : except 5 wards  rest of the  to o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356541</th>\n",
       "      <td>2020-05-01 10:56:09</td>\n",
       "      <td>CSatyarthi</td>\n",
       "      <td>Share to save lives Financial Assistance for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173806</th>\n",
       "      <td>2020-05-01 09:55:03</td>\n",
       "      <td>dailytradingapp</td>\n",
       "      <td>Zoom Corrects Blog Saying It Had 300 M Daily...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338585</th>\n",
       "      <td>2020-05-01 10:50:10</td>\n",
       "      <td>sanode2k</td>\n",
       "      <td>Sweden has defied conventional wisdom and ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276318</th>\n",
       "      <td>2020-05-01 10:29:23</td>\n",
       "      <td>PuneZp</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415091</th>\n",
       "      <td>2020-05-01 11:15:41</td>\n",
       "      <td>LeXavTwit</td>\n",
       "      <td>Spanish official apologises for spraying beach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125755</th>\n",
       "      <td>2020-05-01 09:38:53</td>\n",
       "      <td>KongKongKong16</td>\n",
       "      <td>Armed protesters enter Michigan's state capit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99447</th>\n",
       "      <td>2020-05-01 09:30:03</td>\n",
       "      <td>TheAfrican12</td>\n",
       "      <td>So who thought that AFRICA can also give a so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74191 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date             user  \\\n",
       "14544   2020-05-01 09:01:26           Mbhoy1   \n",
       "382831  2020-05-01 11:04:55      KirkshawsPS   \n",
       "175141  2020-05-01 09:55:30         bfsinews   \n",
       "356541  2020-05-01 10:56:09       CSatyarthi   \n",
       "173806  2020-05-01 09:55:03  dailytradingapp   \n",
       "...                     ...              ...   \n",
       "338585  2020-05-01 10:50:10         sanode2k   \n",
       "276318  2020-05-01 10:29:23           PuneZp   \n",
       "415091  2020-05-01 11:15:41        LeXavTwit   \n",
       "125755  2020-05-01 09:38:53   KongKongKong16   \n",
       "99447   2020-05-01 09:30:03     TheAfrican12   \n",
       "\n",
       "                                                     text  \n",
       "14544    \"We have so far succeeded - in the first &amp...  \n",
       "382831   Have you applied for benefits from the DWP or...  \n",
       "175141    and Pune : except 5 wards  rest of the  to o...  \n",
       "356541  Share to save lives Financial Assistance for C...  \n",
       "173806    Zoom Corrects Blog Saying It Had 300 M Daily...  \n",
       "...                                                   ...  \n",
       "338585   Sweden has defied conventional wisdom and ref...  \n",
       "276318                                                     \n",
       "415091  Spanish official apologises for spraying beach...  \n",
       "125755   Armed protesters enter Michigan's state capit...  \n",
       "99447    So who thought that AFRICA can also give a so...  \n",
       "\n",
       "[74191 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gordon_df = filtereng(gordon_df)\n",
    "gordon_df = gordon_df[gordon_df['is_eng'] == 'True']\n",
    "gordon_df = gordon_df.drop('is_eng',axis=1)\n",
    "gordon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14544</th>\n",
       "      <td>2020-05-01 09:01:26</td>\n",
       "      <td>Mbhoy1</td>\n",
       "      <td>\"We have so far succeeded - in the first &amp;amp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382831</th>\n",
       "      <td>2020-05-01 11:04:55</td>\n",
       "      <td>KirkshawsPS</td>\n",
       "      <td>Have you applied for benefits from the DWP or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175141</th>\n",
       "      <td>2020-05-01 09:55:30</td>\n",
       "      <td>bfsinews</td>\n",
       "      <td>and Pune : except 5 wards  rest of the  to o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356541</th>\n",
       "      <td>2020-05-01 10:56:09</td>\n",
       "      <td>CSatyarthi</td>\n",
       "      <td>Share to save lives Financial Assistance for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173806</th>\n",
       "      <td>2020-05-01 09:55:03</td>\n",
       "      <td>dailytradingapp</td>\n",
       "      <td>Zoom Corrects Blog Saying It Had 300 M Daily...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83682</th>\n",
       "      <td>2020-05-01 09:24:45</td>\n",
       "      <td>EmilyKerrITV</td>\n",
       "      <td>An emotional  at  ambulance station tonight a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338585</th>\n",
       "      <td>2020-05-01 10:50:10</td>\n",
       "      <td>sanode2k</td>\n",
       "      <td>Sweden has defied conventional wisdom and ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415091</th>\n",
       "      <td>2020-05-01 11:15:41</td>\n",
       "      <td>LeXavTwit</td>\n",
       "      <td>Spanish official apologises for spraying beach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125755</th>\n",
       "      <td>2020-05-01 09:38:53</td>\n",
       "      <td>KongKongKong16</td>\n",
       "      <td>Armed protesters enter Michigan's state capit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99447</th>\n",
       "      <td>2020-05-01 09:30:03</td>\n",
       "      <td>TheAfrican12</td>\n",
       "      <td>So who thought that AFRICA can also give a so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71491 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date             user  \\\n",
       "14544   2020-05-01 09:01:26           Mbhoy1   \n",
       "382831  2020-05-01 11:04:55      KirkshawsPS   \n",
       "175141  2020-05-01 09:55:30         bfsinews   \n",
       "356541  2020-05-01 10:56:09       CSatyarthi   \n",
       "173806  2020-05-01 09:55:03  dailytradingapp   \n",
       "...                     ...              ...   \n",
       "83682   2020-05-01 09:24:45     EmilyKerrITV   \n",
       "338585  2020-05-01 10:50:10         sanode2k   \n",
       "415091  2020-05-01 11:15:41        LeXavTwit   \n",
       "125755  2020-05-01 09:38:53   KongKongKong16   \n",
       "99447   2020-05-01 09:30:03     TheAfrican12   \n",
       "\n",
       "                                                     text  \n",
       "14544    \"We have so far succeeded - in the first &amp...  \n",
       "382831   Have you applied for benefits from the DWP or...  \n",
       "175141    and Pune : except 5 wards  rest of the  to o...  \n",
       "356541  Share to save lives Financial Assistance for C...  \n",
       "173806    Zoom Corrects Blog Saying It Had 300 M Daily...  \n",
       "...                                                   ...  \n",
       "83682    An emotional  at  ambulance station tonight a...  \n",
       "338585   Sweden has defied conventional wisdom and ref...  \n",
       "415091  Spanish official apologises for spraying beach...  \n",
       "125755   Armed protesters enter Michigan's state capit...  \n",
       "99447    So who thought that AFRICA can also give a so...  \n",
       "\n",
       "[71491 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gordon_df = gordon_df[gordon_df['text'].str.len() > 5].copy()\n",
    "gordon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14544</th>\n",
       "      <td>2020-05-01 09:01:26</td>\n",
       "      <td>Mbhoy1</td>\n",
       "      <td>\"We have so far succeeded - in the first &amp;amp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382831</th>\n",
       "      <td>2020-05-01 11:04:55</td>\n",
       "      <td>KirkshawsPS</td>\n",
       "      <td>Have you applied for benefits from the DWP or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175141</th>\n",
       "      <td>2020-05-01 09:55:30</td>\n",
       "      <td>bfsinews</td>\n",
       "      <td>and Pune : except 5 wards  rest of the  to o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356541</th>\n",
       "      <td>2020-05-01 10:56:09</td>\n",
       "      <td>CSatyarthi</td>\n",
       "      <td>Share to save lives Financial Assistance for C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173806</th>\n",
       "      <td>2020-05-01 09:55:03</td>\n",
       "      <td>dailytradingapp</td>\n",
       "      <td>Zoom Corrects Blog Saying It Had 300 M Daily...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83682</th>\n",
       "      <td>2020-05-01 09:24:45</td>\n",
       "      <td>EmilyKerrITV</td>\n",
       "      <td>An emotional  at  ambulance station tonight a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338585</th>\n",
       "      <td>2020-05-01 10:50:10</td>\n",
       "      <td>sanode2k</td>\n",
       "      <td>Sweden has defied conventional wisdom and ref...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415091</th>\n",
       "      <td>2020-05-01 11:15:41</td>\n",
       "      <td>LeXavTwit</td>\n",
       "      <td>Spanish official apologises for spraying beach...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125755</th>\n",
       "      <td>2020-05-01 09:38:53</td>\n",
       "      <td>KongKongKong16</td>\n",
       "      <td>Armed protesters enter Michigan's state capit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99447</th>\n",
       "      <td>2020-05-01 09:30:03</td>\n",
       "      <td>TheAfrican12</td>\n",
       "      <td>So who thought that AFRICA can also give a so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71147 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date             user  \\\n",
       "14544   2020-05-01 09:01:26           Mbhoy1   \n",
       "382831  2020-05-01 11:04:55      KirkshawsPS   \n",
       "175141  2020-05-01 09:55:30         bfsinews   \n",
       "356541  2020-05-01 10:56:09       CSatyarthi   \n",
       "173806  2020-05-01 09:55:03  dailytradingapp   \n",
       "...                     ...              ...   \n",
       "83682   2020-05-01 09:24:45     EmilyKerrITV   \n",
       "338585  2020-05-01 10:50:10         sanode2k   \n",
       "415091  2020-05-01 11:15:41        LeXavTwit   \n",
       "125755  2020-05-01 09:38:53   KongKongKong16   \n",
       "99447   2020-05-01 09:30:03     TheAfrican12   \n",
       "\n",
       "                                                     text  \n",
       "14544    \"We have so far succeeded - in the first &amp...  \n",
       "382831   Have you applied for benefits from the DWP or...  \n",
       "175141    and Pune : except 5 wards  rest of the  to o...  \n",
       "356541  Share to save lives Financial Assistance for C...  \n",
       "173806    Zoom Corrects Blog Saying It Had 300 M Daily...  \n",
       "...                                                   ...  \n",
       "83682    An emotional  at  ambulance station tonight a...  \n",
       "338585   Sweden has defied conventional wisdom and ref...  \n",
       "415091  Spanish official apologises for spraying beach...  \n",
       "125755   Armed protesters enter Michigan's state capit...  \n",
       "99447    So who thought that AFRICA can also give a so...  \n",
       "\n",
       "[71147 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gordon_df = gordon_df[gordon_df['text'].str.isspace() == False].copy()\n",
    "gordon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in gordon_df.index:\n",
    "#     print(gordon_df.iloc[i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from torchtext import *\n",
    "from torchtext.data import *\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emotions_list = ['Joy', 'Trust', 'Fear', 'Surprise', 'Sadness', 'Disgust', 'Anger', 'Anticipation', 'Neutral']\n",
    "emotions_list = ['anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust', 'neutral']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3.1\n",
    "txt_field = data.Field(tokenize=word_tokenize, lower=True, include_lengths=True, batch_first=True)\n",
    "label_field = data.Field(sequential=False, use_vocab=False, batch_first=True)\n",
    "\n",
    "# dataset_fields = [('text', txt_field), ('Joy', label_field), \n",
    "#                 ('Trust', label_field), ('Fear', label_field), ('Surprise', label_field), \n",
    "#                 ('Sadness', label_field), ('Disgust', label_field), ('Anger', label_field), \n",
    "#                 ('Anticipation', label_field), ('Neutral', label_field)]\n",
    "\n",
    "dataset_fields = [('text', txt_field), ('anger', label_field), \n",
    "                ('anticipation', label_field), ('disgust', label_field), ('fear', label_field), \n",
    "                ('joy', label_field), ('sadness', label_field), ('surprise', label_field), \n",
    "                ('trust', label_field), ('neutral', label_field)]\n",
    "\n",
    "\n",
    "# train, test= TabularDataset.splits(path='./', train='train.csv', test='valid.csv', format='csv', \n",
    "#     fields = dataset_fields, skip_header=True)\n",
    "\n",
    "train, test= TabularDataset.splits(path='./', train='train-80000.csv', test='valid-80000.csv', format='csv', \n",
    "    fields = dataset_fields, skip_header=True)\n",
    "\n",
    "\n",
    "label_field.build_vocab(train)\n",
    "txt_field.build_vocab(train,vectors=vocab.Vectors(\"glove.840B.300d.txt\"),max_size=20000)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=32, sort_key=lambda x: len(x.text), sort_within_batch=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchWrapper:\n",
    "    def __init__(self, dl, x_var, y_vars):\n",
    "        self.dl, self.x_var, self.y_vars = dl, x_var, y_vars # 传入自变量x列表和因变量y列表\n",
    "\n",
    "    def __iter__(self):\n",
    "        for batch in self.dl:\n",
    "            x = getattr(batch, self.x_var) # 在这个封装中只有一个自变量\n",
    "\n",
    "            if self.y_vars is not None: # 把所有因变量cat成一个向量\n",
    "                temp = [getattr(batch, feat).unsqueeze(1) for feat in self.y_vars]\n",
    "                y = torch.cat(temp, dim=1).float()\n",
    "            else:\n",
    "                y = torch.zeros((1))\n",
    "\n",
    "            yield (x, y)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dl)\n",
    "\n",
    "train_dl = BatchWrapper(train_iter, \"text\", emotions_list)\n",
    "test_dl = BatchWrapper(test_iter, \"text\", emotions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20002"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = len(txt_field.vocab)\n",
    "embedding_dim = 64\n",
    "hidden_dim = 128\n",
    "output_dim = 9\n",
    "dropout = 0.5\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "        self.rnn = nn.LSTM(\n",
    "            input_size=embedding_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, text, text_len):\n",
    "        embedded = self.embedding(text)\n",
    "        output, (last_hidden_state, last_cell_state) = self.rnn(embedded)\n",
    "        linear_input = last_hidden_state[-1]\n",
    "        return self.fc(self.dropout(linear_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    temp = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    print(f'The model architecture:\\n\\n', model)\n",
    "    print(f'\\nThe model has {temp:,} trainable parameters')\n",
    "\n",
    "model = LSTM(input_dim, embedding_dim, hidden_dim, output_dim, dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model architecture:\n",
      "\n",
      " LSTM(\n",
      "  (embedding): Embedding(20002, 64)\n",
      "  (rnn): LSTM(64, 128, batch_first=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (fc): Linear(in_features=128, out_features=9, bias=True)\n",
      ")\n",
      "\n",
      "The model has 1,380,617 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(tensor, y):\n",
    "    preds = torch.round(torch.sigmoid(tensor))\n",
    "    correct = (preds == y).float()\n",
    "    return correct.sum() / len(correct) * 100\n",
    "\n",
    "\n",
    "def save_checkpoint(save_path, model, optimizer, val_loss):\n",
    "    if save_path==None:\n",
    "        return\n",
    "    save_path = save_path \n",
    "    state_dict = {'model_state_dict': model.state_dict(),\n",
    "                  'optimizer_state_dict': optimizer.state_dict(),\n",
    "                  'val_loss': val_loss}\n",
    "    torch.save(state_dict, save_path)\n",
    "    print(f'Model saved to ==> {save_path}')\n",
    "\n",
    "\n",
    "def load_checkpoint(model, optimizer, save_path):\n",
    "    state_dict = torch.load(save_path)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    optimizer.load_state_dict(state_dict['optimizer_state_dict'])\n",
    "    val_loss = state_dict['val_loss']\n",
    "    print(f'Model loaded from <== {save_path}')\n",
    "    return val_loss\n",
    "\n",
    "\n",
    "def TRAIN(net, train_iter, valid_iter, num_epochs, eval_every, total_step, criterion, optimizer, val_loss, device, save_name):\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    running_num = 0\n",
    "    global_step = 0\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    count = []\n",
    "    if val_loss==None:\n",
    "        best_val_loss = float(\"Inf\")  \n",
    "    else: \n",
    "        best_val_loss=val_loss\n",
    "\n",
    "    since = time.time()\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        \n",
    "        for batch in train_iter: ## batch is ((text, text_len_array), 2d_labels), text_len_array hv all same value thx to BucketIterator\n",
    "            \n",
    "            net.train()\n",
    "\n",
    "            '''Training of the model'''\n",
    "            # Forward pass\n",
    "            text = batch[0][0] \n",
    "            text_len = batch[0][1][0].item()\n",
    "            label = batch[1]\n",
    "            \n",
    "            outputs = net(text, text_len).squeeze(1)\n",
    "            loss = criterion(outputs, label)\n",
    "\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            global_step += 1\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            '''Evaluating the model every x steps'''\n",
    "            if global_step % eval_every == 0:\n",
    "                with torch.no_grad():\n",
    "                    net.eval()\n",
    "                    val_running_loss = 0.0\n",
    "                    for val_batch in valid_iter:\n",
    "                        val_text = val_batch[0][0]\n",
    "                        val_text_len = val_batch[0][1][0].item()\n",
    "                        val_label = val_batch[1]\n",
    "                        \n",
    "                        val_outputs = net(val_text, val_text_len).squeeze(1)\n",
    "                        val_loss = criterion(val_outputs, val_label)\n",
    "                        val_running_loss += val_loss.item()\n",
    "\n",
    "                    average_train_loss = running_loss / eval_every\n",
    "                    average_val_loss = val_running_loss / len(valid_iter)\n",
    "                    train_loss.append(average_train_loss)\n",
    "                    valid_loss.append(average_val_loss)\n",
    "                    count.append(global_step)\n",
    "\n",
    "                    print('Epoch [{}/{}], Step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                          .format(epoch+1, num_epochs, global_step, total_step, average_train_loss, average_val_loss))\n",
    "\n",
    "                    running_loss = 0.0\n",
    "                    \n",
    "                    if average_val_loss < best_val_loss:\n",
    "                        best_val_loss = average_val_loss\n",
    "                        save_checkpoint(save_name, net, optimizer, best_val_loss)\n",
    "\n",
    "    print('Finished Training, training time: %.4f' % (time.time() - since))\n",
    "\n",
    "    print('training loss: %.4f\\nvalidation loss: %.4f' % (train_loss[-1], valid_loss[-1]))\n",
    "    plot_x = count\n",
    "    p1, = plt.plot(plot_x, train_loss, color='red', linewidth=1, label='training loss')\n",
    "    p2, = plt.plot(plot_x, valid_loss,  color='blue', linewidth=1, label='validation loss')\n",
    "    plt.legend(handles=[p1, p2], loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('number of evaluation')\n",
    "    plt.title('loss over number of evaluation')\n",
    "    plt.show()\n",
    "\n",
    "    return train_loss, valid_loss\n",
    "\n",
    "\n",
    "def eval(model, iterator):\n",
    "    \n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text = batch[0][0]\n",
    "            text_len = batch[0][1][0].item()\n",
    "            label = batch[1]\n",
    "\n",
    "            outputs = model(text, text_len).squeeze(1)\n",
    "            acc = test_accuracy(outputs, label) / 9\n",
    "\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    avg_acc = epoch_acc / len(iterator)\n",
    "    print(f'Test accuracy: {avg_acc}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTM(input_dim, embedding_dim, hidden_dim, output_dim, dropout).to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "num_epochs = 15\n",
    "eval_every = 1000\n",
    "total_step = len(train_iter)*num_epochs\n",
    "best_val_loss = None\n",
    "save_path = f'tweet_net.pt'\n",
    "\n",
    "# train_loss, valid_loss = TRAIN(model, train_dl, test_dl, num_epochs, eval_every, total_step, criterion, optimizer, \n",
    "#       best_val_loss, device, save_path)\n",
    "\n",
    "#eval(model2, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from <== tweet_net.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.18419405172020198"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_checkpoint(model, optimizer, f'tweet_net.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# gordon_df = pd.read_csv('onlyengandsentimenttotext.csv', encoding='utf8', dtype=str, escapechar='\\\\')\n",
    "\n",
    "\n",
    "def predict_sentence_sentiment(model, sentence):\n",
    "    model.eval()\n",
    "    tokenized = word_tokenize(sentence)\n",
    "    indexed = [txt_field.vocab.stoi[t] for t in tokenized]\n",
    "    length = [len(indexed)]\n",
    "    tensor = torch.LongTensor(indexed)\n",
    "    tensor = tensor.unsqueeze(0)\n",
    "    length_tensor = torch.LongTensor(length)\n",
    "    output = model(tensor.to(device), length_tensor)\n",
    "    prediction = torch.round(torch.sigmoid(output)).int()\n",
    "    return prediction.cpu().numpy()[0]\n",
    "\n",
    "def predict_sentiment(row):\n",
    "    row[emotions_list] = predict_sentence_sentiment(model, row['text'])\n",
    "    return row\n",
    "\n",
    "for e in emotions_list:\n",
    "    gordon_df[e] = 0\n",
    "gordon_df = gordon_df.apply(predict_sentiment, axis=1)\n",
    "gordon_df.to_csv(sentiment_out, header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gordon_df.date = gordon_df.date.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14544</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>Mbhoy1</td>\n",
       "      <td>\"We have so far succeeded - in the first &amp;amp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382831</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>KirkshawsPS</td>\n",
       "      <td>Have you applied for benefits from the DWP or...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175141</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>bfsinews</td>\n",
       "      <td>and Pune : except 5 wards  rest of the  to o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356541</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>CSatyarthi</td>\n",
       "      <td>Share to save lives Financial Assistance for C...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173806</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>dailytradingapp</td>\n",
       "      <td>Zoom Corrects Blog Saying It Had 300 M Daily...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83682</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>EmilyKerrITV</td>\n",
       "      <td>An emotional  at  ambulance station tonight a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338585</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>sanode2k</td>\n",
       "      <td>Sweden has defied conventional wisdom and ref...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415091</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>LeXavTwit</td>\n",
       "      <td>Spanish official apologises for spraying beach...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125755</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>KongKongKong16</td>\n",
       "      <td>Armed protesters enter Michigan's state capit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99447</th>\n",
       "      <td>2020-05-01</td>\n",
       "      <td>TheAfrican12</td>\n",
       "      <td>So who thought that AFRICA can also give a so...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71147 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              date             user  \\\n",
       "14544   2020-05-01           Mbhoy1   \n",
       "382831  2020-05-01      KirkshawsPS   \n",
       "175141  2020-05-01         bfsinews   \n",
       "356541  2020-05-01       CSatyarthi   \n",
       "173806  2020-05-01  dailytradingapp   \n",
       "...            ...              ...   \n",
       "83682   2020-05-01     EmilyKerrITV   \n",
       "338585  2020-05-01         sanode2k   \n",
       "415091  2020-05-01        LeXavTwit   \n",
       "125755  2020-05-01   KongKongKong16   \n",
       "99447   2020-05-01     TheAfrican12   \n",
       "\n",
       "                                                     text  anger  \\\n",
       "14544    \"We have so far succeeded - in the first &amp...      0   \n",
       "382831   Have you applied for benefits from the DWP or...      0   \n",
       "175141    and Pune : except 5 wards  rest of the  to o...      0   \n",
       "356541  Share to save lives Financial Assistance for C...      0   \n",
       "173806    Zoom Corrects Blog Saying It Had 300 M Daily...      0   \n",
       "...                                                   ...    ...   \n",
       "83682    An emotional  at  ambulance station tonight a...      0   \n",
       "338585   Sweden has defied conventional wisdom and ref...      0   \n",
       "415091  Spanish official apologises for spraying beach...      0   \n",
       "125755   Armed protesters enter Michigan's state capit...      0   \n",
       "99447    So who thought that AFRICA can also give a so...      0   \n",
       "\n",
       "        anticipation  disgust  fear  joy  sadness  surprise  trust  neutral  \n",
       "14544              0        0     1    0        1         0      1        0  \n",
       "382831             0        0     0    0        1         0      0        0  \n",
       "175141             0        0     0    0        1         0      0        0  \n",
       "356541             0        0     0    1        0         0      1        0  \n",
       "173806             0        0     0    0        0         0      0        1  \n",
       "...              ...      ...   ...  ...      ...       ...    ...      ...  \n",
       "83682              0        0     0    0        0         0      0        1  \n",
       "338585             0        0     0    0        1         0      1        0  \n",
       "415091             0        0     0    0        0         0      1        0  \n",
       "125755             0        0     0    0        0         0      0        1  \n",
       "99447              1        0     0    0        0         0      0        0  \n",
       "\n",
       "[71147 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def filterTime(row):\n",
    "    row['date'] = row['date'].split(\" \")[0]\n",
    "    return row\n",
    "\n",
    "gordon2_df = gordon_df.apply(filterTime, axis=1)\n",
    "gordon2_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#COVID19</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>11692</td>\n",
       "      <td>16446</td>\n",
       "      <td>6145</td>\n",
       "      <td>18719</td>\n",
       "      <td>10270</td>\n",
       "      <td>13544</td>\n",
       "      <td>7060</td>\n",
       "      <td>19456</td>\n",
       "      <td>28057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            anger  anticipation  disgust   fear    joy  sadness  surprise  \\\n",
       "date                                                                        \n",
       "#COVID19        0             0        0      0      0        0         0   \n",
       "2020-05-01  11692         16446     6145  18719  10270    13544      7060   \n",
       "\n",
       "            trust  neutral  \n",
       "date                        \n",
       "#COVID19        0        1  \n",
       "2020-05-01  19456    28057  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = ['date','anger', 'anticipation', 'disgust', 'fear', 'joy', 'sadness', 'surprise', 'trust', 'neutral']\n",
    "gordon3_df = gordon2_df[arr].groupby('date').sum()\n",
    "gordon3_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "gordon3_df.to_csv(sentiment_date_out, header=True, index=True, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#COVID19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-01</th>\n",
       "      <td>0.088988</td>\n",
       "      <td>0.12517</td>\n",
       "      <td>0.04677</td>\n",
       "      <td>0.14247</td>\n",
       "      <td>0.078165</td>\n",
       "      <td>0.103083</td>\n",
       "      <td>0.053734</td>\n",
       "      <td>0.148079</td>\n",
       "      <td>0.213541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               anger  anticipation  disgust     fear       joy   sadness  \\\n",
       "date                                                                       \n",
       "#COVID19    0.000000       0.00000  0.00000  0.00000  0.000000  0.000000   \n",
       "2020-05-01  0.088988       0.12517  0.04677  0.14247  0.078165  0.103083   \n",
       "\n",
       "            surprise     trust   neutral  \n",
       "date                                      \n",
       "#COVID19    0.000000  0.000000  1.000000  \n",
       "2020-05-01  0.053734  0.148079  0.213541  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gordon4_df = gordon3_df.divide(gordon3_df.sum(axis=1),axis=0)\n",
    "gordon4_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
